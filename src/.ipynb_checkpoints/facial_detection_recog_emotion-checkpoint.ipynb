{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-3-66a2057e92d5>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-66a2057e92d5>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    ï¼pip3 install face_recognition\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "!pip3 install face_recognition\n",
    "import face_recognition\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze> requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = Image.open(\"../test_images/040wrmpyTF5l.jpg\")\n",
    "image_array1 = np.array(image1)\n",
    "plt.imshow(image_array1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting the location of faces from a given image using face_recognition library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = face_recognition.load_image_file(\"../test_images/040wrmpyTF5l.jpg\")\n",
    "\n",
    "face_locations = face_recognition.face_locations(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list of tuples of found face locations in (top, right, bottom, left) order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking the first face detected from image and plotting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top, right, bottom, left = face_locations[0]\n",
    "face_image1 = image[top:bottom, left:right]\n",
    "plt.imshow(face_image1)\n",
    "image_save = Image.fromarray(face_image1)\n",
    "image_save.save(\"image_1.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking the second face detected from image and plotting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top, right, bottom, left = face_locations[1]\n",
    "face_image2 = image[top:bottom, left:right]\n",
    "plt.imshow(face_image2)\n",
    "image_save = Image.fromarray(face_image2)\n",
    "image_save.save(\"image_2.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = Image.open(\"../test_images/index2.jpeg\")\n",
    "image_array1 = np.array(image1)\n",
    "plt.imshow(image_array1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = Image.open(\"../test_images/index1.jpg\")\n",
    "image_array2 = np.array(image2)\n",
    "plt.imshow(image_array2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image3 = Image.open(\"../test_images/rajeev.jpg\")\n",
    "image_array3 = np.array(image3)\n",
    "plt.imshow(image_array3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the face encoding for Image1 and Image2 which is of same person with different pose and compare them to find if they are recognized as same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = face_recognition.load_image_file(\"../test_images/index1.jpg\")\n",
    "image2 = face_recognition.load_image_file(\"../test_images/index2.jpeg\")\n",
    " \n",
    "encoding_1 = face_recognition.face_encodings(image1)[0]\n",
    "\n",
    "encoding_2 = face_recognition.face_encodings(image1)[0]\n",
    "\n",
    "results = face_recognition.compare_faces([encoding_1], encoding_2,tolerance=0.50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the result of the above comparison returns \"True\" stating that two images having different pose are recognized as same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the same is done for Image1 and Image3 which are the images of two persons and the result returned after comparison is \"False\" denoting the two images are not recognized as same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = face_recognition.load_image_file(\"../test_images/index1.jpg\")\n",
    "image2 = face_recognition.load_image_file(\"../test_images/rajeev.jpg\")\n",
    " \n",
    "encoding_1 = face_recognition.face_encodings(image1)[0]\n",
    "\n",
    "encoding_2 = face_recognition.face_encodings(image2)[0]\n",
    "\n",
    "results = face_recognition.compare_faces([encoding_1], encoding_2,tolerance=0.50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict= {'Angry': 0, 'Sad': 5, 'Neutral': 4, 'Disgust': 1, 'Surprise': 6, 'Fear': 2, 'Happy': 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading a sample image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_image  = cv2.imread(\"../test_images/39.jpg\")\n",
    "plt.imshow(face_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The label of this image is \"Surprise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print face_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = face_recognition.load_image_file(\"./fer2013/train/Angry/38.jpg\")\n",
    "# face_locations = face_recognition.face_locations(face_image)\n",
    "# top, right, bottom, left = face_locations[0]\n",
    "# face_image = face_image[top:bottom, left:right]\n",
    "# plt.imshow(face_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizing the image\n",
    "face_image = cv2.resize(face_image, (48,48))\n",
    "face_image = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)\n",
    "face_image = np.reshape(face_image, [1, face_image.shape[0], face_image.shape[1], 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Load the model trained for detecting emotions of a face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"../emotion_detector_models/model_v6_23.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print face_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = np.argmax(model.predict(face_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_map = dict((v,k) for k,v in emotion_dict.items()) \n",
    "predicted_label = label_map[predicted_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
